<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Christopher A. Choquette-Choo</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-155314717-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-155314717-1');
  </script>

  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="author" content="Christopher A. Choquette-Choo">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <!-- Bootstrap core CSS -->
  <link href="css/bootstrap/bootstrap.min.css" rel="stylesheet">

  <link rel="stylesheet" type="text/css" href="css/academicons.min.css">
  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/styleoverrides.css">
  <script src="javascript.js"></script>

  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
  <script src="https://kit.fontawesome.com/c700ff3e4e.js" crossorigin="anonymous"></script>
  <!-- <script src="//code.jquery.com/jquery-1.12.4.min.js"></script> -->
</head>

<body>
<main role="main">

     <div class="jumbotron" style="padding-top: 1.5rem">
        <div class="container">
          <h1 class="media-heading" style="text-align: center">Christopher A. Choquette-Choo</h1>
          <div class="row">
            <div class="col-md-4">
              <img src="images/ChristopherChoquette.jpg" class="rounded img-fluid" alt="Christopher A. Choquette-Choo">
            </div>
            <div class="col-md-8">
                <span class="contacticon center">
                  <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&user=oDE4I64AAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
                  <a href="data/resume.pdf" target="_blank" title="Resume"><i class="ai ai-cv"></i></a>
                  <a href="http://www.github.com/cchoquette" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
                  <a href="http://www.linkedin.com/in/christopher-choquette-choo/" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
                  <a href="https://twitter.com/Chris_Choquette" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>
                  <a href="https://medium.com/@choquette.christopher" target="_blank" title="Blog"><i class="fas fa-blog"></i></a>
                </span>

                <p>I am an AI Resident (2020) at Google on the Mobile Devices and On-Device models team, which includes federated learning and differential privacy.</p>
                <hr/>
                <!--              <p>My research interests are at the intersection of security, privacy, and machine learning. If you would like to learn more about my research, I recommend reading the blog posts I co-authored on <a href="https://www.cleverhans.io/" target="_blank">cleverhans.io</a>, for example about <a href="http://www.cleverhans.io/2020/07/20/unlearning.html" target="_blank">machine unlearning</a>, <a href="http://www.cleverhans.io/privacy/2018/04/29/privacy-and-machine-learning.html" target="_blank">differentially private ML</a>, or <a href="http://www.cleverhans.io/security/privacy/ml/2017/02/15/why-attacking-machine-learning-is-easier-than-defending-it.html" target="_blank">adversarial examples</a>.</p>-->
                <p>Previously, I worked on adversarial machine learning research in the <a href="https://www.papernot.fr/">CleverHans Lab</a> at the Vector Institute. I've worked on deep learning projects, namely <a href="https://arxiv.org/abs/1910.05835">DualDNN</a> while I was at Intel Corp., <a href="https://github.com/tensorflow/privacy/tree/master/tensorflow_privacy/privacy/bolt_on">differential privacy</a> in collaboration with Google's Tensorflow/Privacy, and <a href="https://github.com/georgianpartners/foreshadow">AutoML</a> while I was at <a href="https://georgian.io/">Georgian Partners LP</a>. I graduated with honors from <a href="https://engsci.utoronto.ca/explore_our_program/about_engsci/">Engineering Science</a>, with a major in Robotics, at the University of Toronto, where I had a <b><a href="https://www.schulichleaders.com/christopher-choquette-choo">full scholarship</a></b> for leadership and academic achievement.</p>
              <p class="mt-3 mb-0"><strong>Email:</strong> cchoquette[at]google[dot]com</p>
<!--                <a href="/cdn-cgi/l/email-protection#5d33343e32313c2e732d3c2d382f3332291d2829322f32332932733e3c"><span class="__cf_email__" data-cfemail="4c22252f23202d3f623c2d3c293e2223380c3938233e23223823622f2d">[email&#160;protected]</span></a>-->
<!--              <p>-->
<!--                <a class="btn btn-info" href="https://papernot.fr/papernot_cv.pdf" target="_blank" role="button">CV &raquo;</a>&nbsp;-->
<!--                <a class="btn btn-success" href="http://www.cleverhans.io" target="_blank" role="button">Blog &raquo;</a>&nbsp;-->
<!--                <a class="btn btn-primary" href="https://www.twitter.com/nicolaspapernot" target="_blank" role="button">Twitter &raquo;</a>&nbsp;-->
<!--                <a class="btn btn-dark" href="https://scholar.google.com/citations?user=cGxq0cMAAAAJ&hl=en" target="_blank" role="button">Google Scholar &raquo;</a></p>-->
            </div>
          </div>

        </div>
      </div>
    <div class="jumbotron" style="padding-top: 1.5rem; background:white">
    <div class="container" style="background:white">

       <h4>Research</h4>

        <p>I'm broadly interested in Machine Learning, with a focus on its intersection with security and privacy. Specific areas include adversarial ML, data privacy, deep learning, and collaborative learning. See my <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&user=oDE4I64AAAAJ" target="_blank" title="Google Scholar">google scholar</a> for an up-to-date list.</p>

        <table class="table-striped" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td colspan="2" style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2103.05633">
                  <papertitle>Proof-of-Learning: Definitions</papertitle> <a href="https://github.com/cleverhans-lab/Proof-of-Learning" target="_blank" title="GitHub" style='float: right'><i class="fab fa-github"></i></a>
                </a>
                <br>
              Hengrui Jia^, Mohammad Yaghini^, <b>Christopher A. Choquette-Choo*</b>, Natalie Dullerud*, Anvith Thudi*, Varun Chandrasekaran, Nicolas Papernot
                <br>
              <em>Proceedings of the 42nd IEEE Symposium on Security and Privacy</em>, San Francisco, CA, 2021 <span class="badge badge-primary">conference</span>
                <br>
                <em>^,* Equal contribution. The names are ordered alphabetically.</em>
                <br>
                <p></p>
                <p>How can we prove that a machine learning model owner trained their model? We define the problem of Proof-of-Learning (PoL) in machine learning and provide a method for it that is robust to several spoofing attacks. This protocol enables model ownership verification and robustness against byzantines workers (in a distributed learning setting).</p>
              </td>
            </tr>
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image'><img src='images/capc.png' width="120%"></div></div>
              </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openreview.net/forum?id=h2EbJ4_wMVq">
                  <papertitle>CaPC Learning: Confidential and Private Collaborative Learning</papertitle> <a href="https://github.com/cleverhans-lab/capc-iclr" target="_blank" title="GitHub" style='float: right'><i class="fab fa-github"></i></a>
                </a>
                <br>
                <b>Christopher A. Choquette-Choo*</b>, Natalie Dullerud*, Adam Dziedzic*, Yunxiang Zhang*, Somesh Jha, Nicolas Papernot, Xiao Wang
                <br>
              <em>International Conference on Learning Representations (ICLR)</em> 2021 <span class="badge badge-primary">conference</span>
                <br>
                <em>* Equal contribution. The names are ordered alphabetically.</em>
                <br>
                <p></p>
                <p>We provide a protocol for collaborative learning that ensures privacy of the training data and confidentiality of the test data. Unlike prior work, we enable collaborative learning of heterogeneous models amongst participants and show that our protocol leads to benefits for all parties in standard and balanced accuracies (improved fairness). Unlike differentially private federated learning, which requires ~1 million participants, our protocol can work in regimes of ~100 participants. </p>
              </td>
            </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image'><img src='images/defenseplot.png' width="120%"></div></div>
              </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2007.14321">
                  <papertitle>Label-Only Membership Inference Attacks</papertitle> <a href="https://github.com/label-only/membership-inference" target="_blank" title="GitHub" style='float: right'><i class="fab fa-github"></i></a>
                </a>
                <br>
                <b>Christopher A. Choquette-Choo</b>, Florian Tramèr, Nicholas Carlini, Nicolas Papernot
                <br>
                <em>arXiv pre-print</em> 2020 <span class="badge badge-secondary">pre-print</span>
                <br>
                <p></p>
                <p>We expose and show that <em>confidence-masking</em> -- defensive obfuscation of confidence-vectors -- is not a viable defense to Membership Inference by showing that label-only attacks can bypass this defense and match typical confidence-vector attacks. In an extensive evaluation of defenses, we further show that Differential Privacy can defend against average- and worse-case Membership Inference attacks.</p>
              </td>
            </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image'><img src='images/ewe.png' width="120%"></div></div>
              </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2002.12200">
                  <papertitle>Entangled Watermarks as a Defense against Model Extraction</papertitle> <a href="https://github.com/cleverhans-lab/entangled-watermark" target="_blank" title="GitHub" style='float: right'><i class="fab fa-github"></i></a>
                </a>
                <br>
                Hengrui Jia, <b>Christopher A. Choquette-Choo</b>, Varun Chandrasekaran, Nicolas Papernot
                <br>
                <em>Proceedings of USENIX Security</em> 2021 <span class="badge badge-primary">conference</span>
                <p></p>
                <p>How can we enable an IP owner to reliably claim ownership of a stolen model? We explore entangling of watermarks to task data to ensure that stolen models learn these watermarks as well. Our improved watermarks enable IP owners to claim ownership with 95% confidence in less than 10 queries to the stolen model.</p>
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image'><img src='images/sisa.png' width="120%"></div></div>
              </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1912.03817">
                  <papertitle>Machine Unlearning</papertitle> <a href="https://github.com/cleverhans-lab/machine-unlearning" target="_blank" title="GitHub" style='float: right'><i class="fab fa-github"></i></a>
                </a>
                <br>
                Lucas Bourtoule*, Varun Chandrasekaran*, <b>Christopher A. Choquette-Choo*</b>, Hengrui Jia*, Adelin Travers*, Baiwu Zhang*, David Lie, Nicolas Papernot
                <br>
                <em>Proceedings of the 42nd IEEE Symposium on Security and Privacy</em>, San Francisco, CA, 2021 <span class="badge badge-primary">conference</span>
                <br>
                <em>* Equal contribution. The names are ordered alphabetically.</em>
                <br>
                <p></p>
                <p>How can we minimize the accuracy degradation and computational retraining cost using a true unlearning approach - retraining a model from scratch? We define a stricter unlearning requirement as well as an approach to drastically minimizing these risks in uniform and distribution-aware settings.</p>
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image'><img src='images/neuralnetwork.png' width="120%"></div></div>
             <!--  <script type="text/javascript">
                function nightsight_start() {
                  document.getElementById('nightsight_image').style.opacity = "1";
                }

                function nightsight_stop() {
                  document.getElementById('nightsight_image').style.opacity = "0";
                }
                nightsight_stop()
              </script -->
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1910.05835">
                <papertitle>A multi-label, dual-output deep neural network for automated bug triaging</papertitle>
              </a>
              <br>
              <b>Christopher A. Choquette-Choo</b>, David Sheldon, Jonny Proppe, John Alphonso-Gibbs, Harsha Gupta
              <br>
              <em>ICMLA</em>, 2019  &nbsp|&nbsp DOI: 10.1109/ICMLA.2019.00161 <span class="badge badge-primary">conference</span>
              <br>
              <p></p>
              <p>By utilizing a model's own knowledge of an analogous lower-dimensionality solution-space, we can achieve higher accuracies in a higher-dimensionality solution-space.</p>
            </td>
          </tr>


        </tbody></table>

       <h4>Research Talks</h4>
        <div class="row mb-3">
            <div class="col-sm-8">
                <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:20%;vertical-align:middle"><img src="images/ReWorkVideoSnippet.png" width="100%"></td>
            <td width="70%" valign="center">
              <b>Adversarial Machine Learning: Ensuring Security and Privacy of ML Models and Sensitive Data.</b>
              <br>
              Presented at the REWORK Responsible AI Summit</a> 2019.
              <br>
                Available as a part of the <a href="https://videos.re-work.co/playlists/22-privacy-security">Privacy and Security in Machine Learning</a> package.
            </td>
          </tr>
        </tbody></table>
            </div>
<!--              <div align="center"><b>Adversarial Machine Learning: Ensuring Security and Privacy of ML Models and Sensitive Data.</b></div>-->
<!--                <img src="images/ReWorkVideoSnippet.png" width=100>-->
<!--                Presented at the REWORK Responsible AI Summit 2019 in Montreal.-->
<!--              <br>-->
<!--              Available as a part of the <a href="https://videos.re-work.co/playlists/22-privacy-security">Privacy and Security in Machine Learning</a> package.-->
<!--&lt;!&ndash;                <iframe width="560" height="315" src="http://videos.re-work.co/videos/1763-adversarial-machine-learning-ensuring-security-of-ml-models-and-sensitive-data-christopher-choquette-choo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>&ndash;&gt;-->
<!--            </div>-->
        </div>
        <h4>Professional Services</h4>
        <ul><li>External Reviewer for 2022 USENIX Security Symposium</li><li>External Reviewer for 2022 IEEE Symposium on Security and Privacy</li><li>Reviewer for 2021 Journal of Machine Learning Research</li><li>External Reviewer for 2021 International Conference on Machine Learning (ICML)</li><li>External Reviewer for 2021 USENIX Security Symposium</li><li>External Reviewer for 2021 IEEE Symposium on Security and Privacy</li> <li>Reviewer for the 2020 Machine Learning for the Developing World (ML4D) workshop at NeurIPS</li></ul>
      </div> <!-- /container -->
    </div> <!-- /jumbotron -->
    </main>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="js/bootstrap.min.js"></script>
  </body>
<p style="text-align:right;font-size:small;">This website was based off <a href="https://jonbarron.info/">Jon Barron</a>'s.</p>
</html>
